{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09308ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import nltk\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk import FreqDist\n",
    "from nltk import ConditionalFreqDist\n",
    "import re\n",
    "from nltk import ngrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f0203",
   "metadata": {},
   "source": [
    "## Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad25f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "def preprocess_text(file_path):\n",
    "    # Read the text from the file from line 174 to line 37247\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()[173:37246]  # Read from line 174 to line 37247\n",
    "        text = ''.join(lines)\n",
    "\n",
    "    # Define the pattern to remove chapter headings and titles\n",
    "    chapter_pattern = r'Chapter\\s+[IVXLCDM]+\\.\\s*\\n.*?(?=\\n(?:Chapter\\s+[IVXLCDM]+\\.\\s*|$))'\n",
    "\n",
    "    # Remove chapter headings and titles\n",
    "    text = re.sub(chapter_pattern, '', text)\n",
    "\n",
    "    # Remove punctuation marks other than \".\", \"!\", \"?\"\n",
    "    text = re.sub(r'[^\\w\\s.!?]', '', text)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Remove newlines\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'TheBrothersKaramazov.txt'\n",
    "preprocessed_text = preprocess_text(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c1f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class n_gram_lang_model:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def preprocess_text(self,file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()[173:37246]  \n",
    "            text = ''.join(lines)\n",
    "\n",
    "        chapter_pattern = r'Chapter\\s+[IVXLCDM]+\\.\\s*\\n.*?(?=\\n(?:Chapter\\s+[IVXLCDM]+\\.\\s*|$))'\n",
    "\n",
    "        text = re.sub(chapter_pattern, '', text)\n",
    "\n",
    "        text = re.sub(r'[^\\w\\s.!?]', '', text)\n",
    "\n",
    "    \n",
    "        text = text.replace('\\n', ' ')\n",
    "\n",
    "        return text.strip()\n",
    "    \n",
    "    def add_sos_tokens(self,sentence):\n",
    "        # Split the sentence into words\n",
    "        words = sentence.split()\n",
    "\n",
    "        # Iterate over the words and add three EOS tokens after '.', '?', or '!'\n",
    "        updated_sentence = []\n",
    "        for word in words:\n",
    "            updated_sentence.append(word)\n",
    "            if word.endswith('.') or word.endswith('?') or word.endswith('!'):\n",
    "                updated_sentence.extend([ 'EOS'])\n",
    "\n",
    "        return ' '.join(updated_sentence)\n",
    "\n",
    "    def sentence_tokenize(self,text):\n",
    "        \n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        sentences = [sentence.strip() for sentence in sentences]\n",
    "        \n",
    "        \n",
    "        \n",
    "        sentences_with_eos = []\n",
    "\n",
    "        # Iterate through each sentence\n",
    "        for i in range(len(sentences)):\n",
    "            # Extract the current sentence\n",
    "            current_sentence = sentences[i].strip()\n",
    "\n",
    "\n",
    "            # Append the current sentence to the list\n",
    "            if i == 0:\n",
    "                current_sentence_with_eos = current_sentence + \" <EOS>\"\n",
    "                sentences_with_eos.append(current_sentence_with_eos)\n",
    "\n",
    "            # If it's not the last sentence\n",
    "            if i < len(sentences) - 1:\n",
    "                # Extract the last word of the current sentence\n",
    "                last_word = current_sentence.split()[-1]\n",
    "                sentences_with_eos.append(sentences[i + 1].strip()+ \" <EOS>\")\n",
    "                next_sentence = sentences[i + 1].strip()\n",
    "\n",
    "                # Concatenate the last word of the current sentence with the next sentence\n",
    "                next_sentence_with_start_word = last_word + \" \" + next_sentence\n",
    "\n",
    "                # Append the modified next sentence to the list\n",
    "                sentences_with_eos.append(next_sentence_with_start_word.strip()+ \" <EOS>\")\n",
    "        return sentences_with_eos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "    def n_gram_extractor(self,n,sentences):\n",
    "        Ngram = []\n",
    "        self.n = n\n",
    "        for sent in sentences:\n",
    "            Ngram.extend(list(ngrams(sent.split(' '), self.n, pad_left=True, left_pad_symbol='SOS')))\n",
    "        \n",
    "        #text_n_grams= list(ngrams(text.split(' '), self.n,pad_left=True, left_pad_symbol='SOS'))\n",
    "        #Ngram.extend(text_n_grams)\n",
    "                \n",
    "        return Ngram\n",
    "    \n",
    "    def model_training(self,ngram):\n",
    "        freq_ngram = FreqDist(ngram)\n",
    "        model = ConditionalFreqDist()\n",
    "        for a, b, c,d in freq_ngram:\n",
    "            model[(a,b,c)][d] += freq_ngram[a, b,c,d]\n",
    "\n",
    "        #for phrase in ngram:\n",
    "            #model[phrase[:self.n-1]][phrase[self.n-1]] += freq_ngram[phrase]\n",
    "        return model\n",
    "    \n",
    "    def thresholding(self,model,thresh):\n",
    "    \n",
    "        prob_mat = ConditionalFreqDist()\n",
    "        for keys,vals in model.items():\n",
    "            total = sum(model[keys].values())\n",
    "            for k,v in model[keys].items():\n",
    "                if v > thresh:\n",
    "                    prob_mat[keys][k] = v\n",
    "                    \n",
    "        return prob_mat\n",
    "    \n",
    "    def query_prediction(self,model, input_query,pred_len):\n",
    "        \n",
    "        sent = ' '.join(input_query)\n",
    "        for i in range(pred_len):\n",
    "            if (len(model[input_query])!=0) :\n",
    "            \n",
    "                suffix = pd.DataFrame([i[0] for i in model[input_query].most_common(5)]).sample(1).values[0][0]\n",
    "                sent=sent+' '+ suffix\n",
    "\n",
    "                input_query = sent.split(' ')[1:]\n",
    "                input_query = tuple(input_query)\n",
    "        if input_query[-1] == 'SOS':\n",
    "            input_query\n",
    "        query = sent.replace('SOS', '')\n",
    "        \n",
    "        \n",
    "        return query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190e35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'TheBrothersKaramazov.txt'\n",
    "ngram_model = n_gram_lang_model()\n",
    "preprocessed_text = ngram_model.preprocess_text(file_path)\n",
    "sentences= ngram_model.sentence_tokenize(preprocessed_text)\n",
    "\n",
    "#text = ngram_model.add_sos_tokens(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "18bc2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = ngram_model.n_gram_extractor(4,sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "64db62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ngram_model.model_training(ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "44accf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_mat = ngram_model.thresholding(model,2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d7073f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_input(input_query, prediction):\n",
    "    predicted_words = prediction.split()\n",
    "\n",
    "    updated_input = input_query[1:] + (predicted_words[-1],)\n",
    "    return updated_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0ebc2de3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1: this has so much time to spend on sentimentality with boys.\n",
      "sentence 2: boys. They began teasing Ilusha at once.\n",
      "sentence 3: once. The old man has begun to lock himself in at night and goes grouseshooting in the daytime and thats how he lives.\n",
      "sentence 4: lives. Ive established myself in his room.\n",
      "sentence 5: room. He suddenly pictured the garden the path behind the garden the door of the prison superintendent too who though scrupulous in the performance of his duties was a kind of presentiment of it I am sure some one told you so!\n",
      "sentence 6: so! Why at Mokroe?\n",
      "sentence 7: Mokroe? But its night!\n",
      "sentence 8: night! Once the lad had all now the lad has naught cried Mitya suddenly.\n",
      "sentence 9: suddenly. How can I forgive His tormentors?\n",
      "sentence 10: tormentors? she bids all the saints all the martyrs all the angels and archangels to fall down with her and her unfinished answer left on the table he was a general burst of laughter.\n",
      "sentence 11: laughter. He literally shook with laughter.\n",
      "sentence 12: laughter. Its at him she said pointing to Alyosha with childish vexation at herself for not being able to sham a fit on purpose in my life.\n",
      "sentence 13: life. But we shall tell them that you can sham fits as you boasted then?\n",
      "sentence 14: then? He moved closer so that his knees positively knocked against Alyosha.\n",
      "sentence 15: Alyosha. I have a word with youif only you allow me.\n",
      "sentence 16: me. I saw how they glowed with firea fire of gentle indignation.\n",
      "sentence 17: indignation. This game only tickled that insect lust I cherished in my soul.\n",
      "sentence 18: soul. You almost killed himcursed himand nowhereyoure making jokesYour money or your life!\n",
      "sentence 19: life! So its you Mitya cried Alyosha in surprise violently startled however.\n",
      "sentence 20: however. What do you mean?\n",
      "sentence 21: mean? Alyosha who had been governor of the district council joining the group.\n",
      "sentence 22: group. Theyll acquit him for certain said a resolute voice.\n",
      "sentence 23: voice. He used the word apothecary instead of doctor on purpose and gloat over my anger.\n",
      "sentence 24: anger. Who the devil can make you out?\n",
      "sentence 25: out? No one knew on what terms she was with the retired lieutenant Dmitri Fyodorovitch Karamazov.\n",
      "sentence 26: Karamazov. I see you and dont even hear your voice as I did today.\n",
      "sentence 27: today. Dont be uneasy.\n",
      "sentence 28: uneasy. The public was looking forward with anxious curiosity to the meeting of the family and succeeded in insulting my rival in the presence of the celebrated lawyer Fetyukovitch.\n",
      "sentence 29: Fetyukovitch. He will speak at last and retreated to his former fantastic statements all those are trivialities.\n",
      "sentence 30: trivialities. You must believe it on my left side so as to be able to think at last that freedom and bread enough for all are inconceivable together for never never will they be able to turn his mind from painful thoughts and we began to dream of how we would buy a horse and God has given them the rudiments of thought and conviction and not the real punishment the only effectual one the only deterrent and softening one which lies in the fact that the witness was alive or not yet he had left an astounding piece of newsshe had gone off without telling her and why he left orders with his landlady not to let himself be provoked by vileness but that although he had always looked upon her as she was before 1772.\n",
      "sentence 31: 1772. Come thats better!\n",
      "sentence 32: better! She drew the heavy curtains herself.\n",
      "sentence 33: herself. The counsel Fetyukovitch would have charged more but the case has become so notorious.\n",
      "sentence 34: notorious. I saw him thrusting hurriedly into my hand Thats for you in the future.\n",
      "sentence 35: future. Meanwhile she gave her for present use eighty thousand roubles as soon as Ivan had called her half an hour till its quite red and swollen and whats left in the bottle she gives him to drink with you.\n",
      "sentence 36: you. And Ill never desert you my angel.\n",
      "sentence 37: angel. I might have saved something and did not refuse the generals widow had rewarded him with a terrible fixed stare but it was symbolic theyll say an allegory and the devil are fighting there and the battlefield is the heart of man here on earth.\n",
      "sentence 38: earth. The world stands on absurdities and perhaps nothing would have induced him to tell Katerina Ivanovna so if it could have comforted him.\n",
      "sentence 39: him. He is a man here you might apply to.\n",
      "sentence 40: to. For if youve money Alexey Fyodorovitch you have only to want a thing and you can go.\n",
      "sentence 41: go. But the promise that he would come with that message.\n",
      "sentence 42: message. I knew he wouldnt explain it to you!\n",
      "sentence 43: you! But now Ill be drunk with wine too.\n",
      "sentence 44: too. He said so to me himself.\n",
      "sentence 45: himself. I feel almost certain of that when I am away and bother you.\n",
      "sentence 46: you. And all this we are to believe the evidence of a combination of facts very suggestive though I admit inconclusive.\n",
      "sentence 47: inconclusive. In the first place this Mitya or rather Dmitri Fyodorovitch was the only one of Fyodor Pavlovitchs other two sons and of their origin.\n",
      "sentence 48: origin. Arina Petrovna compose your countenance.\n",
      "sentence 49: countenance. This is Alexey Fyodorovitch Karamazov.\n",
      "sentence 50: Karamazov. I dont quite remember how he used to run about playing the buffoon at other mens tables and was only admitted to the hermitage to keep a sharp look out.\n"
     ]
    }
   ],
   "source": [
    "start = 'this'\n",
    "input_query = ('SOS','SOS','this')\n",
    "text = []\n",
    "num = 0\n",
    "while num<50:    \n",
    "    query = ngram_model.query_prediction(model, input_query,1)\n",
    "    #print(\" \".join(text))\n",
    "    if query.split(' ')[-1] == '<EOS>':\n",
    "        num +=1\n",
    "        input_query = ('SOS','SOS',query.split(' ')[-2])\n",
    "        \n",
    "        print('sentence {}:'.format(num) , start+\" \"+\" \".join(text))\n",
    "        start = query.split(' ')[-2]\n",
    "        text = []\n",
    "        \n",
    "        \n",
    "    else:\n",
    "            \n",
    "        input_query = update_input(input_query, query)\n",
    "        text.append(query.split()[-1])\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a062bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
